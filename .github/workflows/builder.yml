name: builder-docker-image-build

on: 
  push: 

  release:
    types: [created]

jobs:
  build-image:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: add sshkey
        uses: webfactory/ssh-agent@v0.5.2
        with:
          ssh-private-key: ${{ secrets.SSHKEY }}
      - name: builder
        run: |
          sudo apt-get update  
          sudo apt install qemu-user-static g++-arm-linux-gnueabihf kpartx aria2 tree s3fs
          sudo pip install requests
          mkdir images && sudo APIKEY=${{ secrets.APIKEY }} USERNAME=${{ secrets.USERNAME }} PATH=./node_modules/.bin:$PATH ./builder --noninteractive  

          echo "**************Finding image**************"
          image=$(find images/*.img | head -1) 
          [[ -n "$image" ]] || exit 1
          echo "**************Build finish**************"
          release=$(git tag --points-at HEAD | tail -n2 2>/dev/null | sed -e 's/^release-//')
          [[ -z "$release" ]] && echo "Build Successful; no release" >&2 && exit 0
          echo "**************Assigning Variables*************"
          release_is_number() { echo "$release" | grep -Eqx "[0-9]+" ; }
          name="treehouse-$release"
          image_gz="$name.img.gz"
          image_sha1=$image_gz.sha1
          
          image_dir="experiment/"
          if release_is_number; then 
            image_dir="" 
          fi

          echo "**************Compressing image**************"
          bell() { while true; do sleep 60; echo -e "\\a"; done ; }
          bell &
          gzip -c -9 < "$image" > "$image_gz"
          sync
          sha1sum "$image_gz" > "$image_sha1"
          sync

          echo "**************s3fs mounting**************"
          echo "${{ secrets.ACCESS_KEY_ID }}:${{ secrets.SECRET_ACCESS_KEY }}" > .passwd-s3fs
          chmod 600 .passwd-s3fs
          sudo rm -rf /var/www/html
          sudo mkdir -p /var/www/html
          sudo chmod 666 /var/www/html
          sudo s3fs treehouses /var/www/html -o passwd_file=./.passwd-s3fs -o allow_other 
          echo "**************download.treehouses.io**************"
          sudo cp "$image_gz" "$image_sha1" "/var/www/html/$image_dir"
          echo "**************download.ole.org**************"
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "download.ole.org ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBK6diybdi0R/Iptq9qGSP/ZU5zaJ8XrfGSuGvmsVFGKdQAPJsS4GhRm4cq8ucAYoatz9gx/mgJBWgPV6JPbkxiU=" > ~/.ssh/known_hosts
          rsync -Pav "$image_gz" "$image_sha1" deploy@download.ole.org:/data/images/
          if release_is_number; then
            echo "Marking release as latest image"
            ssh deploy@download.ole.org:/data/images/ -c ":; cd /data/images; ln -sf $name.img.gz latest.img.gz; ln -sf $name.img.gz.sha1 latest.img.gz.sha1"
          fi
          echo "**************Copying index file directory**************"
          sudo mv /var/www/html/index.html index.html.old 
          sudo sync 
          sudo systemctl start apache2
          sudo curl http://localhost -o index.html
          sudo mv index.html.old /var/www/html/.
          sudo sync 
          sudo mv ./index.html /var/www/html
          sudo rm /var/www/html/index.html.old 
      - name: invalidate
        uses: chetan/invalidate-cloudfront-action@master
        env:
          DISTRIBUTION: ${{ secrets.DISTRIBUTION }}
          PATHS: '/index.html'
          AWS_REGION: 'us-east-1'
          AWS_ACCESS_KEY_ID: ${{ secrets.ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.SECRET_ACCESS_KEY }}